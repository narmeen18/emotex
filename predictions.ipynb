{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Tweet_lema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we need to do something. something must be don...</td>\n",
       "      <td>0</td>\n",
       "      <td>need something something must doneyour anxiety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Chan_lfc10 @paul_rule @Nuttall1878 @DeadlineD...</td>\n",
       "      <td>0</td>\n",
       "      <td>would fume hijacked 8m move relegate full back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caleb had a nightmare about zombies.</td>\n",
       "      <td>0</td>\n",
       "      <td>caleb nightmare zombies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#CNN really needs to get out of the #Propagand...</td>\n",
       "      <td>0</td>\n",
       "      <td>cnn really need propaganda business 30 second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#dmme #kikme  #sext #horny  #ass #bbw  #naught...</td>\n",
       "      <td>0</td>\n",
       "      <td>dmme kikme sext horny bbw naughty pussy kik nu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Affect Dimension  \\\n",
       "0  we need to do something. something must be don...                 0   \n",
       "1  @Chan_lfc10 @paul_rule @Nuttall1878 @DeadlineD...                 0   \n",
       "2              Caleb had a nightmare about zombies.                  0   \n",
       "3  #CNN really needs to get out of the #Propagand...                 0   \n",
       "4  #dmme #kikme  #sext #horny  #ass #bbw  #naught...                 0   \n",
       "\n",
       "                                          Tweet_lema  \n",
       "0  need something something must doneyour anxiety...  \n",
       "1     would fume hijacked 8m move relegate full back  \n",
       "2                            caleb nightmare zombies  \n",
       "3  cnn really need propaganda business 30 second ...  \n",
       "4  dmme kikme sext horny bbw naughty pussy kik nu...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "data = pd.read_csv('data_clean.csv',encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "Tfidf=TfidfVectorizer()\n",
    "X= data['Tweet_lema']\n",
    "y=data['Affect Dimension']\n",
    "\n",
    "#x=Tfidf.fit_transform(X)\n",
    "X = Tfidf.fit_transform(X.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       402\n",
      "           1       0.69      0.68      0.68       428\n",
      "           2       0.89      0.83      0.86       399\n",
      "           3       0.56      0.65      0.60       361\n",
      "\n",
      "    accuracy                           0.71      1590\n",
      "   macro avg       0.72      0.71      0.71      1590\n",
      "weighted avg       0.72      0.71      0.71      1590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(C=1, degree= 1, gamma= 1, kernel= 'poly', probability= True).fit(X_train,y_train)\n",
    "pred_2= svc.predict(X_test)\n",
    "print(classification_report(y_test,pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text=\"i am afraid\"\n",
    "data=sent_tokenize(text)\n",
    "data\n",
    "abc=Tfidf.transform(data)\n",
    "pred1= svc.predict(abc)\n",
    "\n",
    "print(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter hashtag for search: #party\n",
      "enter number of tweets to analyze: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @chloe3dx: The #NewBasement will welcome yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The #NewBasement will welcome you again this W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @NatureCutsTags: Beekeeping Decal #naturecu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beekeeping Decal #naturecuts #etsy  #etsyshop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @StreetFameRadi1: Interested In Advertising...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  RT @chloe3dx: The #NewBasement will welcome yo...\n",
       "1  The #NewBasement will welcome you again this W...\n",
       "2  RT @NatureCutsTags: Beekeeping Decal #naturecu...\n",
       "3  Beekeeping Decal #naturecuts #etsy  #etsyshop ...\n",
       "4  RT @StreetFameRadi1: Interested In Advertising..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#consumer key, consumer secret, access token, access secret.\n",
    "ckey=\"FpamlkWTozRZhZj1kT8yhZETQ\"\n",
    "csecret=\"7schRUjNUMnccuyoS54OiYA0Ltbulimu2pFhusAbBrg6H43W9u\"\n",
    "atoken=\"1601550698-GfqGB1XueHbOFZKUNeJu3RitRtzOTVdB0GDqHfV\"\n",
    "asecret=\"qiJkpq9WrumCtjMHOR6UG9buJBQyheLS1FjPsXwaSj4KN\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken,asecret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "searchTerm = input(\"enter hashtag for search: \")\n",
    "no_searchTerms = int(input(\"enter number of tweets to analyze: \"))\n",
    "\n",
    "tweets = tweepy.Cursor(api.search, q=searchTerm, lang=\"en\").items(no_searchTerms)\n",
    "\n",
    "tweet_list=[tweet for tweet in tweets]\n",
    "noTweet=0\n",
    "text=[]\n",
    "for tweet in tweet_list:\n",
    "    text.append(tweet.text)\n",
    "   \n",
    "text\n",
    "\n",
    "df= pd.DataFrame(text)\n",
    "df.columns=['Tweet']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @chloe3dx: The #NewBasement will welcome yo...</td>\n",
       "      <td>The NewBasement will welcome you again this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The #NewBasement will welcome you again this W...</td>\n",
       "      <td>The NewBasement will welcome you again this We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @NatureCutsTags: Beekeeping Decal #naturecu...</td>\n",
       "      <td>Beekeeping Decal naturecuts etsy  etsyshop v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beekeeping Decal #naturecuts #etsy  #etsyshop ...</td>\n",
       "      <td>Beekeeping Decal naturecuts etsy  etsyshop vin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @StreetFameRadi1: Interested In Advertising...</td>\n",
       "      <td>Interested In Advertising Your Brand Busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  RT @chloe3dx: The #NewBasement will welcome yo...   \n",
       "1  The #NewBasement will welcome you again this W...   \n",
       "2  RT @NatureCutsTags: Beekeeping Decal #naturecu...   \n",
       "3  Beekeeping Decal #naturecuts #etsy  #etsyshop ...   \n",
       "4  RT @StreetFameRadi1: Interested In Advertising...   \n",
       "\n",
       "                                         Tweet_clean  \n",
       "0    The NewBasement will welcome you again this ...  \n",
       "1  The NewBasement will welcome you again this We...  \n",
       "2    Beekeeping Decal naturecuts etsy  etsyshop v...  \n",
       "3  Beekeeping Decal naturecuts etsy  etsyshop vin...  \n",
       "4    Interested In Advertising Your Brand Busines...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def CleanTxt(text):\n",
    "    #text= str(text).lower() #lowercase\n",
    "    text= re.sub(r'@[A-Za-z0-9\\:]+','',text)\n",
    "    text= re.sub(r'\\_[A-Za-z0-9]+','',text) #remove mentions\n",
    "    text= re.sub(r'#','',text) #remove hashtag\n",
    "    text= re.sub(r'RT','',text) #remove hashtag\n",
    "    text= re.sub(r'http\\S+|www\\.\\S+','',text) #remove hyperlinks \n",
    "    text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text)\n",
    "    \n",
    "    text= text.translate(str.maketrans('','',string.punctuation)) #remove punctuations\n",
    "   \n",
    "    \n",
    "    return text\n",
    "\n",
    "df['Tweet_clean']= df['Tweet'].apply(CleanTxt)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The NewBasement will welcome you again this Wednesday  Toxic tunes this time by   FrontDE and me…\n",
      "[2]\n",
      "The NewBasement will welcome you again this Wednesday  Toxic tunes this time by   Fron… \n",
      "[2]\n",
      "  Beekeeping Decal naturecuts etsy  etsyshop vinyl vinylstickers sticker decals partysupplies party event deco…\n",
      "[0]\n",
      "Beekeeping Decal naturecuts etsy  etsyshop vinyl vinylstickers sticker decals partysupplies party event… \n",
      "[0]\n",
      "  Interested In Advertising Your Brand Business Or Talent On Street Fame TV\n",
      "Get In Touch Now To Get A Quote Back ASAP…\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "for tweet in df['Tweet_clean']:\n",
    "    list1.append(tweet)\n",
    "    \n",
    "s=no_searchTerms\n",
    "for n in range(s) :\n",
    "    print (list1[n])\n",
    "    data1=list1[n]\n",
    "    data=sent_tokenize(data1)\n",
    "    abc=Tfidf.transform(data)\n",
    "    pred12= svc.predict(abc)\n",
    "    print(pred12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
