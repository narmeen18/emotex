{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Tweet_lema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we need to do something. something must be don...</td>\n",
       "      <td>0</td>\n",
       "      <td>need something something must doneyour anxiety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Chan_lfc10 @paul_rule @Nuttall1878 @DeadlineD...</td>\n",
       "      <td>0</td>\n",
       "      <td>would fume hijacked 8m move relegate full back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caleb had a nightmare about zombies.</td>\n",
       "      <td>0</td>\n",
       "      <td>caleb nightmare zombies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#CNN really needs to get out of the #Propagand...</td>\n",
       "      <td>0</td>\n",
       "      <td>cnn really need propaganda business 30 second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#dmme #kikme  #sext #horny  #ass #bbw  #naught...</td>\n",
       "      <td>0</td>\n",
       "      <td>dmme kikme sext horny bbw naughty pussy kik nu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Affect Dimension  \\\n",
       "0  we need to do something. something must be don...                 0   \n",
       "1  @Chan_lfc10 @paul_rule @Nuttall1878 @DeadlineD...                 0   \n",
       "2              Caleb had a nightmare about zombies.                  0   \n",
       "3  #CNN really needs to get out of the #Propagand...                 0   \n",
       "4  #dmme #kikme  #sext #horny  #ass #bbw  #naught...                 0   \n",
       "\n",
       "                                          Tweet_lema  \n",
       "0  need something something must doneyour anxiety...  \n",
       "1     would fume hijacked 8m move relegate full back  \n",
       "2                            caleb nightmare zombies  \n",
       "3  cnn really need propaganda business 30 second ...  \n",
       "4  dmme kikme sext horny bbw naughty pussy kik nu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "data = pd.read_csv('data_clean.csv',encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "Tfidf=TfidfVectorizer()\n",
    "X= data['Tweet_lema']\n",
    "y=data['Affect Dimension']\n",
    "\n",
    "#x=Tfidf.fit_transform(X)\n",
    "X = Tfidf.fit_transform(X.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       402\n",
      "           1       0.69      0.68      0.68       428\n",
      "           2       0.89      0.83      0.86       399\n",
      "           3       0.56      0.65      0.60       361\n",
      "\n",
      "    accuracy                           0.71      1590\n",
      "   macro avg       0.72      0.71      0.71      1590\n",
      "weighted avg       0.72      0.71      0.71      1590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc = svm.SVC(C=1, degree= 1, gamma= 1, kernel= 'poly', probability= True).fit(X_train,y_train)\n",
    "pred_2= svc.predict(X_test)\n",
    "print(classification_report(y_test,pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   =      1\n",
      "0  =   0.18\n",
      "1  =  97.83\n",
      "2  =   0.34\n",
      "3  =   1.65\n",
      "0= anger, 1=fear, 2=joy, 3=sadness\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "text=\"i am afraid\"\n",
    "data=sent_tokenize(text)\n",
    "data\n",
    "abc=Tfidf.transform(data)\n",
    "pred1= svc.predict(abc)\n",
    "probab=svc.predict_proba(abc)\n",
    "classes=svc.classes_\n",
    "#print(np.array(probab))\n",
    "for class_name,probab in zip(classes,probab):\n",
    "    f\"{class_name}: {probab}\"\n",
    "d=pd.DataFrame(probab*100,columns=pred1).apply(lambda x:round(x,2))\n",
    "d[\"classes\"]=classes\n",
    "\n",
    "d.insert(0, '=', ['=','=','=','='])\n",
    "a=(d[['=',int(pred1)]])\n",
    "print(a)\n",
    "\n",
    "print(\"0= anger, 1=fear, 2=joy, 3=sadness\")\n",
    "fig=d.plot(kind=\"bar\",x='classes',y=pred1 )\n",
    "fig.figure.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter hashtag for search: #christmas\n",
      "enter number of tweets to analyze: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @HiIreland: A wintry post #Christmas mornin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st February 2021, 327 days to go! For all the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatieMettner: Allison was a college senior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MSalmanButt_03: \"Those we love never truly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @NicolaYeager: Mary Schmidt's lovely review...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  RT @HiIreland: A wintry post #Christmas mornin...\n",
       "1  1st February 2021, 327 days to go! For all the...\n",
       "2  RT @KatieMettner: Allison was a college senior...\n",
       "3  RT @MSalmanButt_03: \"Those we love never truly...\n",
       "4  RT @NicolaYeager: Mary Schmidt's lovely review..."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#consumer key, consumer secret, access token, access secret.\n",
    "ckey=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "csecret=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "atoken=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "asecret=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken,asecret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "searchTerm = input(\"enter hashtag for search: \")\n",
    "no_searchTerms = int(input(\"enter number of tweets to analyze: \"))\n",
    "\n",
    "tweets = tweepy.Cursor(api.search, q=searchTerm, lang=\"en\").items(no_searchTerms)\n",
    "\n",
    "tweet_list=[tweet for tweet in tweets]\n",
    "noTweet=0\n",
    "text=[]\n",
    "for tweet in tweet_list:\n",
    "    text.append(tweet.text)\n",
    "   \n",
    "text\n",
    "\n",
    "df= pd.DataFrame(text)\n",
    "df.columns=['Tweet']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @HiIreland: A wintry post #Christmas mornin...</td>\n",
       "      <td>A wintry post Christmas morning down in Wick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st February 2021, 327 days to go! For all the...</td>\n",
       "      <td>1st February 2021 327 days to go For all the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatieMettner: Allison was a college senior...</td>\n",
       "      <td>Allison was a college senior ready to gradua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MSalmanButt_03: \"Those we love never truly...</td>\n",
       "      <td>Those we love never truly leave us There are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @NicolaYeager: Mary Schmidt's lovely review...</td>\n",
       "      <td>Mary Schmidts lovely review of A Recipe for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  RT @HiIreland: A wintry post #Christmas mornin...   \n",
       "1  1st February 2021, 327 days to go! For all the...   \n",
       "2  RT @KatieMettner: Allison was a college senior...   \n",
       "3  RT @MSalmanButt_03: \"Those we love never truly...   \n",
       "4  RT @NicolaYeager: Mary Schmidt's lovely review...   \n",
       "\n",
       "                                         Tweet_clean  \n",
       "0    A wintry post Christmas morning down in Wick...  \n",
       "1  1st February 2021 327 days to go For all the l...  \n",
       "2    Allison was a college senior ready to gradua...  \n",
       "3    Those we love never truly leave us There are...  \n",
       "4    Mary Schmidts lovely review of A Recipe for ...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def CleanTxt(text):\n",
    "    #text= str(text).lower() #lowercase\n",
    "    text= re.sub(r'@[A-Za-z0-9\\:]+','',text)\n",
    "    text= re.sub(r'\\_[A-Za-z0-9]+','',text) #remove mentions\n",
    "    text= re.sub(r'#','',text) #remove hashtag\n",
    "    text= re.sub(r'RT','',text) #remove hashtag\n",
    "    text= re.sub(r'http\\S+|www\\.\\S+','',text) #remove hyperlinks \n",
    "    text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text)\n",
    "    \n",
    "    text= text.translate(str.maketrans('','',string.punctuation)) #remove punctuations\n",
    "   \n",
    "    \n",
    "    return text\n",
    "\n",
    "df['Tweet_clean']= df['Tweet'].apply(CleanTxt)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @GINIQGIN: #Whisky #Whiskey #Malt #Gin #Oxf...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gluten free Chocolate Fudge Cake baked for a s...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Club_DanceRadio: play music https://t.co/g...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @blazing_night: Christmas party Frank pins ...</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Club_DanceRadio: play music https://t.co/g...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet emotion\n",
       "0  RT @GINIQGIN: #Whisky #Whiskey #Malt #Gin #Oxf...   Angry\n",
       "1  Gluten free Chocolate Fudge Cake baked for a s...  Joy   \n",
       "2  RT @Club_DanceRadio: play music https://t.co/g...  Joy   \n",
       "3  RT @blazing_night: Christmas party Frank pins ...  Fear  \n",
       "4  RT @Club_DanceRadio: play music https://t.co/g...  Joy   "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_emo(pred):\n",
    "    switcher={\n",
    "        0: \"Angry\",\n",
    "        1: \"Fear  \",\n",
    "        2: \"Joy   \",\n",
    "        3: \"Sad   \",\n",
    "        }\n",
    "    \n",
    "    return switcher.get(pred,\"nothing\")\n",
    "    \n",
    "list1=[]\n",
    "emotion=[]\n",
    "for tweet in df['Tweet_clean']:\n",
    "    list1.append(tweet)\n",
    "    \n",
    "s=no_searchTerms\n",
    "for n in range(s) :\n",
    "    #print (list1[n])\n",
    "    data1=list1[n]\n",
    "    data=sent_tokenize(data1)\n",
    "    abc=Tfidf.transform(data)\n",
    "    pred12= int(svc.predict(abc))\n",
    "    #print(pred12)\n",
    "    emotion.append(to_emo(pred12))\n",
    "    \n",
    "    \n",
    "#print(emotion)\n",
    "#print(list1)\n",
    "data_tuples = list(zip(text,emotion))\n",
    "data_tuples\n",
    "Tweet_anatysis=pd.DataFrame(data_tuples, columns=['Tweet','emotion'])\n",
    "\n",
    "Tweet_anatysis.to_csv('./Tweet_anatysis.csv', index=False)\n",
    "Tweet_anatysis.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import svm\n",
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "import tkinter.ttk as ttk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "from PIL import ImageTk,Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "win=Tk()\n",
    "win.geometry(\"900x650\")\n",
    "win.title(\"Emotion Classifier\")\n",
    "win.configure(background=\"light blue\")\n",
    "win.resizable(0,0)\n",
    "canvas=Canvas(win)\n",
    "canvas.create_line(300, 35, 300, 200, dash=(4, 2))\n",
    "frame1 = Frame(win,background=\"light blue\")\n",
    "frame1.place(y=390,x=100,height=240, width=370)\n",
    "#frame2 = Frame(win,background=\"light blue\")\n",
    "#frame2.place(x=490, y=140,height=150, width=300)\n",
    "\n",
    "fr = Frame(win,background=\"light blue\", relief=\"solid\")\n",
    "\n",
    "label_head=Label(win,text=\"Emotion Classifier\",width=\"300\",height=\"2\",font=(\"Calibri 20 bold underline\"), bg='#3d9bb8').pack()\n",
    "#----------Labels\n",
    "text_1=Label(win,text=\"Enter text: \", font=(\"Calibri 12\"),background=\"light blue\", relief=RIDGE).place(x=40, y=100)\n",
    "#Button(win, text= \"Enter\", font=(\"Calibri 12\")).place(x=370, y=97)\n",
    "\n",
    "text_Prediction=Label(win,text=\"Predicted emotion:  \", font=(\"Calibri 12\"),bg=\"light blue\", relief=RIDGE).place(x=40, y=150)\n",
    "\n",
    "#----------Extry of string text\n",
    "Enter_text=StringVar() \n",
    "Entry(win, text=Enter_text ,width=30).place(x=170, y=105)\n",
    "\n",
    "def to_emo(pred):\n",
    "    switcher={\n",
    "        0: \"Angry\",\n",
    "        1: \"Fear  \",\n",
    "        2: \"Joy   \",\n",
    "        3: \"Sad   \",\n",
    "        }\n",
    "    \n",
    "    return switcher.get(pred,\"nothing\")\n",
    "\n",
    "#--------------graph and percentage\n",
    "   \n",
    "def graph():\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        data=sent_tokenize(Enter_text.get())\n",
    "        abc=Tfidf.transform(data)\n",
    "        pred1= svc.predict(abc)\n",
    "        probab=svc.predict_proba(abc)\n",
    "        classes=svc.classes_\n",
    "        #print(np.array(probab))\n",
    "        for class_name,probab in zip(classes,probab):\n",
    "            f\"{class_name}: {probab}\"\n",
    "        d=pd.DataFrame(probab*100,columns=pred1).apply(lambda x:round(x,2))\n",
    "        d[\"classes\"]=classes\n",
    "    \n",
    "        #d.set_index('classes')\n",
    "        d.insert(0, '=', ['=','=','=','='])\n",
    "        a=(d[['=',int(pred1)]])\n",
    "\n",
    "        #print(d.head())\n",
    "        #fr = Frame(win,background=\"blue\", relief=\"solid\")\n",
    "        #fr.place(x=480, y=135,height=450, width=390)\n",
    "        label_percent=Label(win,text=a,font=(\"Calibri 11\"),background='#b7e3f7',width=12, relief='solid').place(x=718, y=448)\n",
    "        l=Label(win,text=\"Emotion:\", font=(\"Calibri 11\"),background='#b7e3f7').place(x=720, y=450)\n",
    "        Label(win,text=\"Key: 0= anger, 1=fear, 2=joy, 3=sadness\", font=(\"Calibri 12\"),background=\"light blue\").place(x=510, y=545)\n",
    "\n",
    "\n",
    "    \n",
    "        figure = plt.Figure(figsize=(6,5), dpi=60)\n",
    "        ax = figure.add_subplot(111)\n",
    "        chart_type = FigureCanvasTkAgg(figure, win)\n",
    "        chart_type.get_tk_widget().place(x=490, y=140)\n",
    "        #df = d[['classes',pred1]].groupby(pred1).sum()\n",
    "        d.plot(kind='bar', x='classes',y=pred1, legend=True, ax=ax)\n",
    "        #d.plot(kind=\"bar\",x='classes',y=pred1 )\n",
    "        ax.set_title('Emotion Confidence graph')\n",
    "        #elif len(Enter_text.get())== 0 :\n",
    "        #Label(win,text='--- Text not entered ---', font=(\"Calibri 12\"),background=\"light blue\", fg='red').place(x=180, y=150)\n",
    "    except:\n",
    "        fr.place(x=480, y=135,height=450, width=390)\n",
    "        Label(win,text='--- Text not entered --- \\n Enter one sentence only', font=(\"Calibri 12\"),background=\"light blue\", fg='red').place(x=500, y=150)\n",
    "   \n",
    "        \n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "#------------prediction function\n",
    "def result():\n",
    "    try:\n",
    "    #if len(Enter_text.get())>0:\n",
    "        Label(win,text='                                                 \\n                                                       ',background=\"light blue\",).place(x=180, y=150)\n",
    "        #data= data.translate(str.maketrans('','',string.punctuation)) #remove punctuations\n",
    "        data=sent_tokenize(Enter_text.get())\n",
    "        \n",
    "        abc=Tfidf.transform(data)\n",
    "        pred= int(svc.predict(abc))\n",
    "        frame2 = Frame(win,background=\"light blue\")\n",
    "        frame2.place(x=480, y=135,height=450, width=390)\n",
    "        \n",
    "    \n",
    "\n",
    "        Label(win,text=str(to_emo(pred)), font=(\"Calibri 12\"),background=\"light blue\").place(x=180, y=150)\n",
    "    except:\n",
    "    #elif len(Enter_text.get())== 0 :\n",
    "        Label(win,text='--- Text not entered --- \\n Enter one sentence only', font=(\"Calibri 12\"),background=\"light blue\", fg='red').place(x=180, y=145)\n",
    "        frame2 = Frame(win,background=\"light blue\")\n",
    "        frame2.place(x=480, y=135,height=450, width=390)\n",
    "\n",
    "    \n",
    "Button(win, text= \"Enter\", font=(\"Calibri 12 \"),background=\"grey\", fg=\"white\", command=result).place(x=368, y=97)\n",
    "Button(win, text= \"graph\", font=(\"Calibri 12 \"),background=\"grey\", fg=\"white\", command=graph).place(x=417, y=97)\n",
    "#Label(win,text=\"Key:   0= anger, 1=fear, 2=joy, 3=sadness\", font=(\"Calibri 12\"),background=\"light blue\", relief=RIDGE).place(x=510, y=100)\n",
    "\n",
    "#for tweets\n",
    "label_tweet=Label(win,text=\"Emotion Classifier for live streaming tweets\",font=(\"Calibri 18 bold\"),background='#3d9bb8', relief='solid').place(x=30, y=190)\n",
    "#--------------Labels\n",
    "Label(win,text=\"Enter Hashtag: \", font=(\"Calibri 12\"),background=\"light blue\", relief=RIDGE).place(x=40, y=240)\n",
    "Label(win,text=\"Enter no. of tweets: \",background=\"light blue\", font=(\"Calibri 12\"), relief=RIDGE).place(x=40, y=270)\n",
    "\n",
    "#---------------Entry\n",
    "Enter_hashtag=StringVar() \n",
    "Enter_number=StringVar()\n",
    "Entry(win, text=Enter_hashtag ,width=30).place(x=200, y=240)\n",
    "Entry(win, text=Enter_number ,width=30).place(x=200, y=270)\n",
    "\n",
    "#def vali():\n",
    " #   if()\n",
    "def to_emo(pred):\n",
    "    switcher={\n",
    "        0: \"Angry\",\n",
    "        1: \"Fear  \",\n",
    "        2: \"Joy   \",\n",
    "        3: \"Sad   \",\n",
    "        }\n",
    "    \n",
    "    return switcher.get(pred,\"nothing\")\n",
    "# function for extraction of tweets\n",
    "def extract():\n",
    "    try:\n",
    "        Label(win,text='                                           ', font=(\"Calibri 12\"),background=\"light blue\", fg='red').place(x=180, y=305)\n",
    "    \n",
    "        clear_data()\n",
    "        #consumer key, consumer secret, access token, access secret.\n",
    "        ckey=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "        csecret=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "        atoken=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "        asecret=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "        auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "        auth.set_access_token(atoken,asecret)\n",
    "        api = tweepy.API(auth)\n",
    "        hashtag=Enter_hashtag.get()\n",
    "        number= int(Enter_number.get())\n",
    "\n",
    "        tweets = tweepy.Cursor(api.search, q=hashtag, lang=\"en\").items(number)\n",
    "\n",
    "        tweet_list=[tweet for tweet in tweets]\n",
    "        noTweet=0\n",
    "        text=[]\n",
    "        for tweet in tweet_list:\n",
    "            text.append(tweet.text)\n",
    "   \n",
    "    #print(text)\n",
    "\n",
    "        df= pd.DataFrame(text)\n",
    "        df.columns=['Tweet']\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "        def CleanTxt(text):\n",
    "    #text= str(text).lower() #lowercase\n",
    "            text= re.sub(r'@[A-Za-z0-9\\:]+','',text)\n",
    "            text= re.sub(r'\\_[A-Za-z0-9]+','',text) #remove mentions\n",
    "            text= re.sub(r'#','',text) #remove hashtag\n",
    "            text= re.sub(r'RT','',text) #remove hashtag\n",
    "            text= re.sub(r'http\\S+|www\\.\\S+','',text) #remove hyperlinks \n",
    "            text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text)\n",
    "    \n",
    "            text= text.translate(str.maketrans('','',string.punctuation)) #remove punctuations\n",
    "   \n",
    "    \n",
    "            return text\n",
    "\n",
    "        df['Tweet_clean']= df['Tweet'].apply(CleanTxt)\n",
    "\n",
    "        df.head()\n",
    "\n",
    "    \n",
    "        list1=[]\n",
    "        emotion=[]\n",
    "        for tweet in df['Tweet_clean']:\n",
    "            list1.append(tweet)\n",
    "    \n",
    "    #s=no_searchTerms\n",
    "        for n in range(number) :\n",
    "    #print (list1[n])\n",
    "            data1=list1[n]\n",
    "            data=sent_tokenize(data1)\n",
    "            abc=Tfidf.transform(data)\n",
    "            pred12= int(svc.predict(abc))\n",
    "\n",
    "            emotion.append(to_emo(pred12))\n",
    "    \n",
    "\n",
    "\n",
    "        data_tuples = list(zip(text,emotion))\n",
    "        data_tuples\n",
    "        Tweet_anatysis=pd.DataFrame(data_tuples, columns=['Tweet','emotion'])\n",
    "\n",
    "        Tweet_anatysis.to_csv('./Tweet_anatysis.csv', index=False)\n",
    "\n",
    "        file_path = './Tweet_anatysis.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        tv1[\"column\"] = list(df.columns)\n",
    "        tv1[\"show\"] = \"headings\"\n",
    "        for column in tv1[\"columns\"]:\n",
    "            tv1.heading(column, text=column) #column heading = column name\n",
    "\n",
    "        df_rows = df.to_numpy().tolist() \n",
    "        for row in df_rows:\n",
    "            tv1.insert(\"\", \"end\", values=row) \n",
    "    except:\n",
    "        Label(win,text='--- Text not entered ---', font=(\"Calibri 12\"),background=\"light blue\", fg='red').place(x=180, y=305)\n",
    "    \n",
    "    return None\n",
    "    #Tweet_a.head()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def clear_data():\n",
    "    tv1.delete(*tv1.get_children())\n",
    "    return None\n",
    "\n",
    "# Treeview Widget\n",
    "tv1 = ttk.Treeview(frame1)\n",
    "tv1.place(relheight=1, relwidth=1) \n",
    "\n",
    "treescrolly = Scrollbar(frame1, orient=\"vertical\", command=tv1.yview) # command means update the yaxis \n",
    "treescrollx = Scrollbar(frame1, orient=\"horizontal\", command=tv1.xview) # command to update the xaxis \n",
    "tv1.configure(xscrollcommand=treescrollx.set, yscrollcommand=treescrolly.set) # scrollbars \n",
    "treescrolly.pack(side=\"right\", fill=\"y\") # make the scrollbar fill the y axis of the Treeview widget\n",
    "treescrollx.pack(side=\"bottom\", fill=\"x\") # make the scrollbar fill the x axis of the Treeview widget\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "B_1= Button(win, text= \"Enter\", font=(\"Calibri 12\"), background=\"grey\", fg=\"white\",command=extract).place(x=370, y=305)\n",
    "\n",
    "Label(win,text=\"Predicted emotion:  \", font=(\"Calibri 12\"),background=\"light blue\",relief=RIDGE).place(x=40, y=350)\n",
    "\n",
    "\n",
    "\n",
    "Button(win, text= \"Exit\", font=(\"Calibri 12 bold\"),background=\"grey\", fg=\"white\",width=12, command=win.destroy).place(x=730, y=600)\n",
    "\n",
    "\n",
    "\n",
    "win.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
